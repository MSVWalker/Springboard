{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41387ac3",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "- [Load combined_df CSV](#Load-combined_df-csv)\n",
    "- [Top 50 Correlations with Glucose](#Top-50-correlations-with-glucose)\n",
    "- [Add log_features for Improved Correlations with Glucose](#Add-log_features-for-improved-correlations-with-glucose)\n",
    "- [Add Minutes and Hours from Midnight](#Add-minutes-and-hours-from-midnight)\n",
    "- [Add Day of Month and Is Weekend](#Add-day-of-month-and-is-weekend)\n",
    "- [Add Time Since Starting](#Add-time-since-starting)\n",
    "- [Add Day Period (Night, Morning, Afternoon, Evening) and One-Hot Encode](#Add-day-period-night-morning-afternoon-evening-and-one-hot-encode)\n",
    "- [Add Accumulative Sum Rolling Statistics](#Add-accumulative-sum-rolling-statistics)\n",
    "- [Add Rolling Statistics for Calories, Protein, Sugar, and Carbs](#Add-rolling-statistics-for-calories-protein-sugar-and-carbs)\n",
    "- [Add Eat Counts Rolling Sum Window](#Add-eat-counts-rolling-sum-window)\n",
    "- [Add 'WakeTime' Points Calculator](#Add-waketime-points-calculator)\n",
    "- [Add 'ActivityBouts' and Rolling Window Mean and Sum](#Add-activitybouts-and-rolling-window-mean-and-sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T22:19:52.148566Z",
     "start_time": "2024-07-17T22:19:52.142791Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n"
   ],
   "outputs": [],
   "execution_count": 121
  },
  {
   "cell_type": "markdown",
   "id": "f9553a9810609742",
   "metadata": {},
   "source": [
    "Load combined_df csv"
   ]
  },
  {
   "cell_type": "code",
   "id": "897ec51ddfe88ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T22:19:52.913826Z",
     "start_time": "2024-07-17T22:19:52.556576Z"
    }
   },
   "source": [
    "combined_df = pd.read_csv('combined_df.csv')\n",
    "combined_df['datetime'] = pd.to_datetime(combined_df['datetime'])\n",
    "\n",
    "# Setting 'datetime' as the index\n",
    "combined_df.set_index('datetime', inplace=True)\n"
   ],
   "outputs": [],
   "execution_count": 122
  },
  {
   "cell_type": "code",
   "id": "85dba4b6dfe30c9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T22:19:52.941304Z",
     "start_time": "2024-07-17T22:19:52.916421Z"
    }
   },
   "source": [
    "feature_df = combined_df.copy()\n",
    "feature_df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                     glucose  patient_id  Gender  HbA1c   acc_mean  bvp_mean  \\\n",
       "datetime                                                                       \n",
       "2020-02-13 17:23:32     61.0           1       0    5.5  87.095625 -0.004786   \n",
       "2020-02-13 17:28:32     59.0           1       0    5.5  88.107187 -0.001255   \n",
       "2020-02-13 17:33:32     58.0           1       0    5.5  57.597604  0.020368   \n",
       "2020-02-13 17:38:32     59.0           1       0    5.5  66.899687 -0.009613   \n",
       "2020-02-13 17:43:31     63.0           1       0    5.5  29.774792 -0.012741   \n",
       "\n",
       "                     eda_mean    hr_mean  ibi_mean  temp_mean  ...  \\\n",
       "datetime                                                       ...   \n",
       "2020-02-13 17:23:32  0.848050  82.318333  0.713904  33.171867  ...   \n",
       "2020-02-13 17:28:32  0.632578  75.429167  0.837369  33.136333  ...   \n",
       "2020-02-13 17:33:32  1.544714  75.973400  0.777253  33.244767  ...   \n",
       "2020-02-13 17:38:32  1.839445  77.138967  0.808537  33.315067  ...   \n",
       "2020-02-13 17:43:31  4.880899  81.056267  0.760995  33.660067  ...   \n",
       "\n",
       "                     food_dietary_fiber  food_sugar  food_protein  \\\n",
       "datetime                                                            \n",
       "2020-02-13 17:23:32                 0.0         0.0           0.0   \n",
       "2020-02-13 17:28:32                 0.0         0.0           0.0   \n",
       "2020-02-13 17:33:32                 0.0         0.0           0.0   \n",
       "2020-02-13 17:38:32                 0.0         0.0           0.0   \n",
       "2020-02-13 17:43:31                 0.0         0.0           0.0   \n",
       "\n",
       "                     food_total_fat  food_calorie_ffwd  food_total_carb_ffwd  \\\n",
       "datetime                                                                       \n",
       "2020-02-13 17:23:32             0.0                0.0                   0.0   \n",
       "2020-02-13 17:28:32             0.0                0.0                   0.0   \n",
       "2020-02-13 17:33:32             0.0                0.0                   0.0   \n",
       "2020-02-13 17:38:32             0.0                0.0                   0.0   \n",
       "2020-02-13 17:43:31             0.0                0.0                   0.0   \n",
       "\n",
       "                     food_dietary_fiber_ffwd  food_sugar_ffwd  \\\n",
       "datetime                                                        \n",
       "2020-02-13 17:23:32                      0.0              0.0   \n",
       "2020-02-13 17:28:32                      0.0              0.0   \n",
       "2020-02-13 17:33:32                      0.0              0.0   \n",
       "2020-02-13 17:38:32                      0.0              0.0   \n",
       "2020-02-13 17:43:31                      0.0              0.0   \n",
       "\n",
       "                     food_protein_ffwd  food_total_fat_ffwd  \n",
       "datetime                                                     \n",
       "2020-02-13 17:23:32                0.0                  0.0  \n",
       "2020-02-13 17:28:32                0.0                  0.0  \n",
       "2020-02-13 17:33:32                0.0                  0.0  \n",
       "2020-02-13 17:38:32                0.0                  0.0  \n",
       "2020-02-13 17:43:31                0.0                  0.0  \n",
       "\n",
       "[5 rows x 88 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>glucose</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>Gender</th>\n",
       "      <th>HbA1c</th>\n",
       "      <th>acc_mean</th>\n",
       "      <th>bvp_mean</th>\n",
       "      <th>eda_mean</th>\n",
       "      <th>hr_mean</th>\n",
       "      <th>ibi_mean</th>\n",
       "      <th>temp_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>food_dietary_fiber</th>\n",
       "      <th>food_sugar</th>\n",
       "      <th>food_protein</th>\n",
       "      <th>food_total_fat</th>\n",
       "      <th>food_calorie_ffwd</th>\n",
       "      <th>food_total_carb_ffwd</th>\n",
       "      <th>food_dietary_fiber_ffwd</th>\n",
       "      <th>food_sugar_ffwd</th>\n",
       "      <th>food_protein_ffwd</th>\n",
       "      <th>food_total_fat_ffwd</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-13 17:23:32</th>\n",
       "      <td>61.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>87.095625</td>\n",
       "      <td>-0.004786</td>\n",
       "      <td>0.848050</td>\n",
       "      <td>82.318333</td>\n",
       "      <td>0.713904</td>\n",
       "      <td>33.171867</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-13 17:28:32</th>\n",
       "      <td>59.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>88.107187</td>\n",
       "      <td>-0.001255</td>\n",
       "      <td>0.632578</td>\n",
       "      <td>75.429167</td>\n",
       "      <td>0.837369</td>\n",
       "      <td>33.136333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-13 17:33:32</th>\n",
       "      <td>58.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>57.597604</td>\n",
       "      <td>0.020368</td>\n",
       "      <td>1.544714</td>\n",
       "      <td>75.973400</td>\n",
       "      <td>0.777253</td>\n",
       "      <td>33.244767</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-13 17:38:32</th>\n",
       "      <td>59.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>66.899687</td>\n",
       "      <td>-0.009613</td>\n",
       "      <td>1.839445</td>\n",
       "      <td>77.138967</td>\n",
       "      <td>0.808537</td>\n",
       "      <td>33.315067</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-13 17:43:31</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>29.774792</td>\n",
       "      <td>-0.012741</td>\n",
       "      <td>4.880899</td>\n",
       "      <td>81.056267</td>\n",
       "      <td>0.760995</td>\n",
       "      <td>33.660067</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 88 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 123
  },
  {
   "cell_type": "markdown",
   "id": "4e53605bd49d803",
   "metadata": {},
   "source": [
    "Print Top 50 Correlations wrt Glucose"
   ]
  },
  {
   "cell_type": "code",
   "id": "e141743c6d157d2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T22:19:53.396484Z",
     "start_time": "2024-07-17T22:19:52.942926Z"
    }
   },
   "source": [
    "# Compute correlation of 'glucose' with other columns\n",
    "# Calculate correlations\n",
    "correlations = feature_df.corr()['glucose']\n",
    "\n",
    "# Sort correlations by absolute value, but keep the original positive/negative correlations\n",
    "sorted_correlations = correlations.reindex(correlations.abs().sort_values(ascending=False).index)\n",
    "\n",
    "# Top 30 correlations\n",
    "top_30_correlations = sorted_correlations.head(50)\n",
    "\n",
    "print(top_30_correlations)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glucose                 1.000000\n",
      "Gender                  0.288043\n",
      "HbA1c                   0.192463\n",
      "acc_x_max              -0.174532\n",
      "acc_x_q3               -0.166453\n",
      "acc_x_2hr_mean         -0.163795\n",
      "food_sugar_ffwd         0.161010\n",
      "eda_max                -0.156942\n",
      "acc_x_mean             -0.153588\n",
      "eda_mean               -0.150663\n",
      "eda_q3                 -0.148611\n",
      "eda_q1                 -0.138039\n",
      "acc_z_std              -0.132580\n",
      "acc_x_q1               -0.131232\n",
      "eda_min                -0.126083\n",
      "acc_std                -0.123440\n",
      "acc_max                -0.123220\n",
      "acc_z_min               0.121160\n",
      "acc_y_std              -0.119563\n",
      "acc_y_min               0.117117\n",
      "acc_x_2hr_max          -0.113518\n",
      "eda_std                -0.107351\n",
      "acc_y_max              -0.104682\n",
      "temp_mean               0.103961\n",
      "temp_min                0.103736\n",
      "temp_q1                 0.102528\n",
      "acc_x_std              -0.101636\n",
      "acc_2hr_mean           -0.098238\n",
      "temp_q3                 0.097006\n",
      "acc_q3                 -0.095201\n",
      "food_total_carb_ffwd    0.095014\n",
      "temp_max                0.094233\n",
      "acc_z_max              -0.093840\n",
      "ibi_q1                  0.091913\n",
      "acc_2hr_max            -0.088666\n",
      "hr_mean                -0.087197\n",
      "ibi_mean                0.085672\n",
      "hr_q1                  -0.085350\n",
      "hr_q3                  -0.083560\n",
      "hr_max                 -0.078264\n",
      "ibi_q3                  0.078035\n",
      "hr_min                 -0.076797\n",
      "acc_z_q1                0.074537\n",
      "acc_y_2hr_max          -0.073535\n",
      "eda_peaks              -0.068470\n",
      "ibi_min                 0.068116\n",
      "ibi_max                 0.067143\n",
      "acc_z_2hr_max          -0.066133\n",
      "acc_min                 0.060286\n",
      "acc_mean               -0.057378\n",
      "Name: glucose, dtype: float64\n"
     ]
    }
   ],
   "execution_count": 124
  },
  {
   "cell_type": "markdown",
   "id": "bb8701c3aa4efcc5",
   "metadata": {},
   "source": [
    "Add log_features for Improved Correlations wrt Glucose"
   ]
  },
  {
   "cell_type": "code",
   "id": "d31c166427de5053",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T22:19:54.433195Z",
     "start_time": "2024-07-17T22:19:53.399237Z"
    }
   },
   "source": [
    "log_feature_df = feature_df.copy()\n",
    "\n",
    "for column in log_feature_df.columns:\n",
    "    # Apply transformation only to columns with number data types and not 'glucose'\n",
    "    if column != 'glucose':\n",
    "        # Shift values by minimum value, resulting in all values being positive\n",
    "        minimum_value = log_feature_df[column].min()\n",
    "        shifted_data = log_feature_df[column] - minimum_value + 1\n",
    "\n",
    "        # Apply log (x + 1) transformation after shifting to positive numbers\n",
    "        log_feature_df['log_' + column] = np.log1p(shifted_data)\n",
    "\n",
    "# Get columns excluding 'glucose' for correlation calculation\n",
    "regular_columns = [col for col in log_feature_df.columns if col != 'glucose' and not col.startswith('log_')]\n",
    "\n",
    "# Calculate correlations for regular values\n",
    "corr_regular = log_feature_df[regular_columns + ['glucose']].corr()['glucose'].drop('glucose')\n",
    "\n",
    "# Calculate correlations for logged values\n",
    "logged_columns = ['log_' + col for col in regular_columns]\n",
    "corr_logged = log_feature_df[logged_columns + ['glucose']].corr()['glucose'].drop('glucose')\n",
    "\n",
    "# Remove 'log_' prefix from logged_columns for matching with regular_columns\n",
    "corr_logged.index = [col.replace('log_', '') for col in corr_logged.index]\n",
    "\n",
    "# Create DataFrame with correlations (the correlations are matched by index which represents column names)\n",
    "corr_df_feature = pd.DataFrame({\n",
    "    'Regular': corr_regular,\n",
    "    'Logged': corr_logged,\n",
    "    'Difference': corr_regular.sub(corr_logged)\n",
    "})\n",
    "\n",
    "# Drop rows with missing values\n",
    "corr_df_feature = corr_df_feature.dropna()\n",
    "\n",
    "# Apply rounding to the 'Difference' column\n",
    "corr_df_feature['Difference'] = corr_df_feature['Difference'].round(5)\n",
    "\n",
    "corr_df_feature = corr_df_feature.sort_values(by='Difference', ascending=False)\n",
    "print(corr_df_feature.head(20))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Regular    Logged  Difference\n",
      "eda_peaks      -0.068470 -0.176900     0.10843\n",
      "eda_max        -0.156942 -0.200720     0.04378\n",
      "eda_q3         -0.148611 -0.191998     0.04339\n",
      "eda_std        -0.107351 -0.150452     0.04310\n",
      "eda_mean       -0.150663 -0.189144     0.03848\n",
      "eda_q1         -0.138039 -0.171331     0.03329\n",
      "acc_z_min       0.121160  0.097877     0.02328\n",
      "bvp_max        -0.006486 -0.027003     0.02052\n",
      "acc_2hr_mean   -0.098238 -0.117762     0.01952\n",
      "eda_min        -0.126083 -0.143918     0.01784\n",
      "acc_x_min       0.025982  0.008747     0.01723\n",
      "hr_std         -0.046776 -0.061350     0.01457\n",
      "acc_q1         -0.009362 -0.023424     0.01406\n",
      "acc_z_mean      0.041923  0.028678     0.01324\n",
      "temp_std       -0.038539 -0.051138     0.01260\n",
      "acc_z_2hr_mean  0.030364  0.018937     0.01143\n",
      "acc_x_q1       -0.131232 -0.142517     0.01129\n",
      "acc_2hr_max    -0.088666 -0.099568     0.01090\n",
      "acc_x_skew      0.005894 -0.003421     0.00932\n",
      "acc_z_q1        0.074537  0.065915     0.00862\n"
     ]
    }
   ],
   "execution_count": 125
  },
  {
   "cell_type": "code",
   "id": "7fcdb774bfdb42dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T22:19:54.447825Z",
     "start_time": "2024-07-17T22:19:54.433941Z"
    }
   },
   "source": [
    "for column in ['eda_peaks', 'eda_max', 'eda_q3', 'eda_std', 'eda_mean', 'eda_q1', 'bvp_max', 'acc_2hr_mean', 'hr_std', 'temp_std']:\n",
    "    # Shift values by minimum value, resulting in all values being positive\n",
    "    minimum_value = feature_df[column].min()\n",
    "    shifted_data = feature_df[column] - minimum_value + 1\n",
    "\n",
    "    # Apply log (x + 1) transformation after shifting to positive numbers\n",
    "    feature_df['log_' + column] = np.log1p(shifted_data)"
   ],
   "outputs": [],
   "execution_count": 126
  },
  {
   "cell_type": "markdown",
   "id": "1688fb357872fbaf",
   "metadata": {},
   "source": [
    "Add Minutes and Hours from midnight"
   ]
  },
  {
   "cell_type": "code",
   "id": "945a6ce6f99b2e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T22:19:54.455606Z",
     "start_time": "2024-07-17T22:19:54.449036Z"
    }
   },
   "source": [
    "feature_df['minutesfrommidnight'] = feature_df.index.hour * 60 + feature_df.index.minute\n",
    "feature_df['hoursfrommidnight'] = feature_df.index.hour + feature_df.index.minute / 60\n"
   ],
   "outputs": [],
   "execution_count": 127
  },
  {
   "cell_type": "markdown",
   "id": "ff025568c32e6a17",
   "metadata": {},
   "source": [
    "Add day of month, is weekend, time since starting"
   ]
  },
  {
   "cell_type": "code",
   "id": "34ffcc4f3a6e4dc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T22:19:54.474388Z",
     "start_time": "2024-07-17T22:19:54.457488Z"
    }
   },
   "source": [
    "\n",
    "# Calculate day of month and is_weekend based on the index\n",
    "feature_df['day_of_month'] = feature_df.index.day\n",
    "feature_df['is_weekend'] = (feature_df.index.dayofweek >= 5).astype(int)\n",
    "\n",
    "# Group by 'patient_id' and apply these calculations\n",
    "grouped = feature_df.groupby('patient_id')\n",
    "\n",
    "# Calculate minutes since the first timestamp for each patient\n",
    "feature_df['minutes_since_start'] = grouped['day_of_month'].transform(lambda x: (x.index - x.index[0]).total_seconds() // 60)\n",
    "\n",
    "# Apply transformations within each group\n",
    "feature_df['day_of_month'] = grouped['day_of_month'].transform('first')\n",
    "feature_df['is_weekend'] = grouped['is_weekend'].transform('first')"
   ],
   "outputs": [],
   "execution_count": 128
  },
  {
   "cell_type": "code",
   "id": "fb164d6dc7feb876",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T22:19:54.488739Z",
     "start_time": "2024-07-17T22:19:54.475472Z"
    }
   },
   "source": [
    "feature_df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                     glucose  patient_id  Gender  HbA1c   acc_mean  bvp_mean  \\\n",
       "datetime                                                                       \n",
       "2020-02-13 17:23:32     61.0           1       0    5.5  87.095625 -0.004786   \n",
       "2020-02-13 17:28:32     59.0           1       0    5.5  88.107187 -0.001255   \n",
       "2020-02-13 17:33:32     58.0           1       0    5.5  57.597604  0.020368   \n",
       "2020-02-13 17:38:32     59.0           1       0    5.5  66.899687 -0.009613   \n",
       "2020-02-13 17:43:31     63.0           1       0    5.5  29.774792 -0.012741   \n",
       "\n",
       "                     eda_mean    hr_mean  ibi_mean  temp_mean  ...  \\\n",
       "datetime                                                       ...   \n",
       "2020-02-13 17:23:32  0.848050  82.318333  0.713904  33.171867  ...   \n",
       "2020-02-13 17:28:32  0.632578  75.429167  0.837369  33.136333  ...   \n",
       "2020-02-13 17:33:32  1.544714  75.973400  0.777253  33.244767  ...   \n",
       "2020-02-13 17:38:32  1.839445  77.138967  0.808537  33.315067  ...   \n",
       "2020-02-13 17:43:31  4.880899  81.056267  0.760995  33.660067  ...   \n",
       "\n",
       "                     log_eda_q1  log_bvp_max  log_acc_2hr_mean  log_hr_std  \\\n",
       "datetime                                                                     \n",
       "2020-02-13 17:23:32    0.773137     4.441121          4.142556    1.771230   \n",
       "2020-02-13 17:28:32    0.869040     4.174233          4.159768    2.255793   \n",
       "2020-02-13 17:33:32    1.241180     5.312713          4.151693    2.396628   \n",
       "2020-02-13 17:38:32    1.321212     4.874357          4.150230    1.842102   \n",
       "2020-02-13 17:43:31    1.781383     4.624581          4.141265    1.937087   \n",
       "\n",
       "                     log_temp_std  minutesfrommidnight  hoursfrommidnight  \\\n",
       "datetime                                                                    \n",
       "2020-02-13 17:23:32      0.814958                 1043          17.383333   \n",
       "2020-02-13 17:28:32      0.808358                 1048          17.466667   \n",
       "2020-02-13 17:33:32      0.715160                 1053          17.550000   \n",
       "2020-02-13 17:38:32      0.723041                 1058          17.633333   \n",
       "2020-02-13 17:43:31      0.759979                 1063          17.716667   \n",
       "\n",
       "                     day_of_month  is_weekend  minutes_since_start  \n",
       "datetime                                                            \n",
       "2020-02-13 17:23:32            13           0                  0.0  \n",
       "2020-02-13 17:28:32            13           0                  5.0  \n",
       "2020-02-13 17:33:32            13           0                 10.0  \n",
       "2020-02-13 17:38:32            13           0                 15.0  \n",
       "2020-02-13 17:43:31            13           0                 19.0  \n",
       "\n",
       "[5 rows x 103 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>glucose</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>Gender</th>\n",
       "      <th>HbA1c</th>\n",
       "      <th>acc_mean</th>\n",
       "      <th>bvp_mean</th>\n",
       "      <th>eda_mean</th>\n",
       "      <th>hr_mean</th>\n",
       "      <th>ibi_mean</th>\n",
       "      <th>temp_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>log_eda_q1</th>\n",
       "      <th>log_bvp_max</th>\n",
       "      <th>log_acc_2hr_mean</th>\n",
       "      <th>log_hr_std</th>\n",
       "      <th>log_temp_std</th>\n",
       "      <th>minutesfrommidnight</th>\n",
       "      <th>hoursfrommidnight</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>minutes_since_start</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-13 17:23:32</th>\n",
       "      <td>61.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>87.095625</td>\n",
       "      <td>-0.004786</td>\n",
       "      <td>0.848050</td>\n",
       "      <td>82.318333</td>\n",
       "      <td>0.713904</td>\n",
       "      <td>33.171867</td>\n",
       "      <td>...</td>\n",
       "      <td>0.773137</td>\n",
       "      <td>4.441121</td>\n",
       "      <td>4.142556</td>\n",
       "      <td>1.771230</td>\n",
       "      <td>0.814958</td>\n",
       "      <td>1043</td>\n",
       "      <td>17.383333</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-13 17:28:32</th>\n",
       "      <td>59.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>88.107187</td>\n",
       "      <td>-0.001255</td>\n",
       "      <td>0.632578</td>\n",
       "      <td>75.429167</td>\n",
       "      <td>0.837369</td>\n",
       "      <td>33.136333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.869040</td>\n",
       "      <td>4.174233</td>\n",
       "      <td>4.159768</td>\n",
       "      <td>2.255793</td>\n",
       "      <td>0.808358</td>\n",
       "      <td>1048</td>\n",
       "      <td>17.466667</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-13 17:33:32</th>\n",
       "      <td>58.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>57.597604</td>\n",
       "      <td>0.020368</td>\n",
       "      <td>1.544714</td>\n",
       "      <td>75.973400</td>\n",
       "      <td>0.777253</td>\n",
       "      <td>33.244767</td>\n",
       "      <td>...</td>\n",
       "      <td>1.241180</td>\n",
       "      <td>5.312713</td>\n",
       "      <td>4.151693</td>\n",
       "      <td>2.396628</td>\n",
       "      <td>0.715160</td>\n",
       "      <td>1053</td>\n",
       "      <td>17.550000</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-13 17:38:32</th>\n",
       "      <td>59.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>66.899687</td>\n",
       "      <td>-0.009613</td>\n",
       "      <td>1.839445</td>\n",
       "      <td>77.138967</td>\n",
       "      <td>0.808537</td>\n",
       "      <td>33.315067</td>\n",
       "      <td>...</td>\n",
       "      <td>1.321212</td>\n",
       "      <td>4.874357</td>\n",
       "      <td>4.150230</td>\n",
       "      <td>1.842102</td>\n",
       "      <td>0.723041</td>\n",
       "      <td>1058</td>\n",
       "      <td>17.633333</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-13 17:43:31</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>29.774792</td>\n",
       "      <td>-0.012741</td>\n",
       "      <td>4.880899</td>\n",
       "      <td>81.056267</td>\n",
       "      <td>0.760995</td>\n",
       "      <td>33.660067</td>\n",
       "      <td>...</td>\n",
       "      <td>1.781383</td>\n",
       "      <td>4.624581</td>\n",
       "      <td>4.141265</td>\n",
       "      <td>1.937087</td>\n",
       "      <td>0.759979</td>\n",
       "      <td>1063</td>\n",
       "      <td>17.716667</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 103 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 129
  },
  {
   "cell_type": "markdown",
   "id": "404a79a95204f630",
   "metadata": {},
   "source": [
    "Add Night, Morning, Afternoon, Evening and one-hot code"
   ]
  },
  {
   "cell_type": "code",
   "id": "1c96fd3e5e267c79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T22:19:54.537725Z",
     "start_time": "2024-07-17T22:19:54.490626Z"
    }
   },
   "source": [
    "# Assuming your index has a datetime component, and it's the first level of the MultiIndex\n",
    "feature_df.index = feature_df.index.get_level_values(0)\n",
    "\n",
    "# Extract hour from datetime index\n",
    "feature_df['hour_of_day'] = feature_df.index.hour\n",
    "\n",
    "# Define function to categorize day period\n",
    "def get_day_period(hour):\n",
    "    if 0 <= hour < 6:\n",
    "        return 'Night'\n",
    "    elif 6 <= hour < 12:\n",
    "        return 'Morning'\n",
    "    elif 12 <= hour < 18:\n",
    "        return 'Afternoon'\n",
    "    else:  # 18 <= hour < 24\n",
    "        return 'Evening'\n",
    "\n",
    "# Apply the function to 'hour_of_day' to create 'day_period' column\n",
    "feature_df['day_period'] = feature_df['hour_of_day'].apply(get_day_period)\n",
    "\n",
    "# Drop the 'hour_of_day' column as it is no longer needed\n",
    "feature_df.drop('hour_of_day', axis=1, inplace=True)\n",
    "\n",
    "# Get dummy variables for 'day_period' and drop the original 'day_period' column\n",
    "feature_df = pd.get_dummies(feature_df, columns=['day_period'])\n",
    "\n",
    "# Convert new one-hot encoded columns to integers\n",
    "for column in feature_df.columns:\n",
    "    if 'day_period' in column:  # this checks if 'day_period' is in the column name\n",
    "        feature_df[column] = feature_df[column].astype(int)\n"
   ],
   "outputs": [],
   "execution_count": 130
  },
  {
   "cell_type": "code",
   "id": "de8d9d78ab1a54e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T22:19:54.554012Z",
     "start_time": "2024-07-17T22:19:54.541615Z"
    }
   },
   "source": [
    "feature_df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                     glucose  patient_id  Gender  HbA1c   acc_mean  bvp_mean  \\\n",
       "datetime                                                                       \n",
       "2020-02-13 17:23:32     61.0           1       0    5.5  87.095625 -0.004786   \n",
       "2020-02-13 17:28:32     59.0           1       0    5.5  88.107187 -0.001255   \n",
       "2020-02-13 17:33:32     58.0           1       0    5.5  57.597604  0.020368   \n",
       "2020-02-13 17:38:32     59.0           1       0    5.5  66.899687 -0.009613   \n",
       "2020-02-13 17:43:31     63.0           1       0    5.5  29.774792 -0.012741   \n",
       "\n",
       "                     eda_mean    hr_mean  ibi_mean  temp_mean  ...  \\\n",
       "datetime                                                       ...   \n",
       "2020-02-13 17:23:32  0.848050  82.318333  0.713904  33.171867  ...   \n",
       "2020-02-13 17:28:32  0.632578  75.429167  0.837369  33.136333  ...   \n",
       "2020-02-13 17:33:32  1.544714  75.973400  0.777253  33.244767  ...   \n",
       "2020-02-13 17:38:32  1.839445  77.138967  0.808537  33.315067  ...   \n",
       "2020-02-13 17:43:31  4.880899  81.056267  0.760995  33.660067  ...   \n",
       "\n",
       "                     log_temp_std  minutesfrommidnight  hoursfrommidnight  \\\n",
       "datetime                                                                    \n",
       "2020-02-13 17:23:32      0.814958                 1043          17.383333   \n",
       "2020-02-13 17:28:32      0.808358                 1048          17.466667   \n",
       "2020-02-13 17:33:32      0.715160                 1053          17.550000   \n",
       "2020-02-13 17:38:32      0.723041                 1058          17.633333   \n",
       "2020-02-13 17:43:31      0.759979                 1063          17.716667   \n",
       "\n",
       "                     day_of_month  is_weekend  minutes_since_start  \\\n",
       "datetime                                                             \n",
       "2020-02-13 17:23:32            13           0                  0.0   \n",
       "2020-02-13 17:28:32            13           0                  5.0   \n",
       "2020-02-13 17:33:32            13           0                 10.0   \n",
       "2020-02-13 17:38:32            13           0                 15.0   \n",
       "2020-02-13 17:43:31            13           0                 19.0   \n",
       "\n",
       "                     day_period_Afternoon  day_period_Evening  \\\n",
       "datetime                                                        \n",
       "2020-02-13 17:23:32                     1                   0   \n",
       "2020-02-13 17:28:32                     1                   0   \n",
       "2020-02-13 17:33:32                     1                   0   \n",
       "2020-02-13 17:38:32                     1                   0   \n",
       "2020-02-13 17:43:31                     1                   0   \n",
       "\n",
       "                     day_period_Morning  day_period_Night  \n",
       "datetime                                                   \n",
       "2020-02-13 17:23:32                   0                 0  \n",
       "2020-02-13 17:28:32                   0                 0  \n",
       "2020-02-13 17:33:32                   0                 0  \n",
       "2020-02-13 17:38:32                   0                 0  \n",
       "2020-02-13 17:43:31                   0                 0  \n",
       "\n",
       "[5 rows x 107 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>glucose</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>Gender</th>\n",
       "      <th>HbA1c</th>\n",
       "      <th>acc_mean</th>\n",
       "      <th>bvp_mean</th>\n",
       "      <th>eda_mean</th>\n",
       "      <th>hr_mean</th>\n",
       "      <th>ibi_mean</th>\n",
       "      <th>temp_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>log_temp_std</th>\n",
       "      <th>minutesfrommidnight</th>\n",
       "      <th>hoursfrommidnight</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>minutes_since_start</th>\n",
       "      <th>day_period_Afternoon</th>\n",
       "      <th>day_period_Evening</th>\n",
       "      <th>day_period_Morning</th>\n",
       "      <th>day_period_Night</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-13 17:23:32</th>\n",
       "      <td>61.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>87.095625</td>\n",
       "      <td>-0.004786</td>\n",
       "      <td>0.848050</td>\n",
       "      <td>82.318333</td>\n",
       "      <td>0.713904</td>\n",
       "      <td>33.171867</td>\n",
       "      <td>...</td>\n",
       "      <td>0.814958</td>\n",
       "      <td>1043</td>\n",
       "      <td>17.383333</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-13 17:28:32</th>\n",
       "      <td>59.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>88.107187</td>\n",
       "      <td>-0.001255</td>\n",
       "      <td>0.632578</td>\n",
       "      <td>75.429167</td>\n",
       "      <td>0.837369</td>\n",
       "      <td>33.136333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.808358</td>\n",
       "      <td>1048</td>\n",
       "      <td>17.466667</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-13 17:33:32</th>\n",
       "      <td>58.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>57.597604</td>\n",
       "      <td>0.020368</td>\n",
       "      <td>1.544714</td>\n",
       "      <td>75.973400</td>\n",
       "      <td>0.777253</td>\n",
       "      <td>33.244767</td>\n",
       "      <td>...</td>\n",
       "      <td>0.715160</td>\n",
       "      <td>1053</td>\n",
       "      <td>17.550000</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-13 17:38:32</th>\n",
       "      <td>59.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>66.899687</td>\n",
       "      <td>-0.009613</td>\n",
       "      <td>1.839445</td>\n",
       "      <td>77.138967</td>\n",
       "      <td>0.808537</td>\n",
       "      <td>33.315067</td>\n",
       "      <td>...</td>\n",
       "      <td>0.723041</td>\n",
       "      <td>1058</td>\n",
       "      <td>17.633333</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-13 17:43:31</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>29.774792</td>\n",
       "      <td>-0.012741</td>\n",
       "      <td>4.880899</td>\n",
       "      <td>81.056267</td>\n",
       "      <td>0.760995</td>\n",
       "      <td>33.660067</td>\n",
       "      <td>...</td>\n",
       "      <td>0.759979</td>\n",
       "      <td>1063</td>\n",
       "      <td>17.716667</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 107 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 131
  },
  {
   "cell_type": "markdown",
   "id": "19b861cbb921469a",
   "metadata": {},
   "source": [
    "Add accumulative sum rolling statics for calories, protein, sugar, and carbs"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T22:19:54.560450Z",
     "start_time": "2024-07-17T22:19:54.555873Z"
    }
   },
   "cell_type": "code",
   "source": "feature_df.food_calorie.dtype",
   "id": "25c49a30b8d4af2c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 132
  },
  {
   "cell_type": "code",
   "id": "160656172e664f3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T22:19:54.783599Z",
     "start_time": "2024-07-17T22:19:54.561994Z"
    }
   },
   "source": [
    "def calculate_and_store_rolling_stats(df, columns_to_roll, time_windows):\n",
    "    for column in columns_to_roll:\n",
    "        for window in time_windows:\n",
    "            new_column_name = f'{column}_sum_{window * 5}min'\n",
    "            \n",
    "            # Calculate rolling sum directly without lambda function\n",
    "            df[new_column_name] = df.groupby('patient_id')[column].rolling(window=window, min_periods=1).sum().values\n",
    "            \n",
    "            # Fill NaN values in the new column with 0\n",
    "            df[new_column_name].fillna(0, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# List of columns for which to calculate rolling statistics\n",
    "columns_to_roll = ['food_calorie', 'food_protein', 'food_sugar', 'food_total_carb']\n",
    "\n",
    "# Define time window(s) in terms of number of periods (5-minute intervals)\n",
    "time_windows = [2, 6, 12, 24, 48, 96, 288]\n",
    "\n",
    "# Compute and store rolling statistics in the dataframe\n",
    "feature_df = calculate_and_store_rolling_stats(feature_df, columns_to_roll, time_windows)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mn/5t8x6ck57719dt2pg7h0_xl40000gn/T/ipykernel_22199/2775434147.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[new_column_name].fillna(0, inplace=True)\n",
      "/var/folders/mn/5t8x6ck57719dt2pg7h0_xl40000gn/T/ipykernel_22199/2775434147.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[new_column_name].fillna(0, inplace=True)\n",
      "/var/folders/mn/5t8x6ck57719dt2pg7h0_xl40000gn/T/ipykernel_22199/2775434147.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[new_column_name].fillna(0, inplace=True)\n",
      "/var/folders/mn/5t8x6ck57719dt2pg7h0_xl40000gn/T/ipykernel_22199/2775434147.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[new_column_name].fillna(0, inplace=True)\n",
      "/var/folders/mn/5t8x6ck57719dt2pg7h0_xl40000gn/T/ipykernel_22199/2775434147.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[new_column_name].fillna(0, inplace=True)\n",
      "/var/folders/mn/5t8x6ck57719dt2pg7h0_xl40000gn/T/ipykernel_22199/2775434147.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[new_column_name].fillna(0, inplace=True)\n",
      "/var/folders/mn/5t8x6ck57719dt2pg7h0_xl40000gn/T/ipykernel_22199/2775434147.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[new_column_name].fillna(0, inplace=True)\n",
      "/var/folders/mn/5t8x6ck57719dt2pg7h0_xl40000gn/T/ipykernel_22199/2775434147.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[new_column_name].fillna(0, inplace=True)\n",
      "/var/folders/mn/5t8x6ck57719dt2pg7h0_xl40000gn/T/ipykernel_22199/2775434147.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[new_column_name].fillna(0, inplace=True)\n",
      "/var/folders/mn/5t8x6ck57719dt2pg7h0_xl40000gn/T/ipykernel_22199/2775434147.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[new_column_name].fillna(0, inplace=True)\n",
      "/var/folders/mn/5t8x6ck57719dt2pg7h0_xl40000gn/T/ipykernel_22199/2775434147.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[new_column_name].fillna(0, inplace=True)\n",
      "/var/folders/mn/5t8x6ck57719dt2pg7h0_xl40000gn/T/ipykernel_22199/2775434147.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[new_column_name].fillna(0, inplace=True)\n",
      "/var/folders/mn/5t8x6ck57719dt2pg7h0_xl40000gn/T/ipykernel_22199/2775434147.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[new_column_name].fillna(0, inplace=True)\n",
      "/var/folders/mn/5t8x6ck57719dt2pg7h0_xl40000gn/T/ipykernel_22199/2775434147.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[new_column_name].fillna(0, inplace=True)\n",
      "/var/folders/mn/5t8x6ck57719dt2pg7h0_xl40000gn/T/ipykernel_22199/2775434147.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[new_column_name].fillna(0, inplace=True)\n",
      "/var/folders/mn/5t8x6ck57719dt2pg7h0_xl40000gn/T/ipykernel_22199/2775434147.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[new_column_name].fillna(0, inplace=True)\n",
      "/var/folders/mn/5t8x6ck57719dt2pg7h0_xl40000gn/T/ipykernel_22199/2775434147.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[new_column_name].fillna(0, inplace=True)\n",
      "/var/folders/mn/5t8x6ck57719dt2pg7h0_xl40000gn/T/ipykernel_22199/2775434147.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[new_column_name].fillna(0, inplace=True)\n",
      "/var/folders/mn/5t8x6ck57719dt2pg7h0_xl40000gn/T/ipykernel_22199/2775434147.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[new_column_name].fillna(0, inplace=True)\n",
      "/var/folders/mn/5t8x6ck57719dt2pg7h0_xl40000gn/T/ipykernel_22199/2775434147.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[new_column_name].fillna(0, inplace=True)\n",
      "/var/folders/mn/5t8x6ck57719dt2pg7h0_xl40000gn/T/ipykernel_22199/2775434147.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[new_column_name].fillna(0, inplace=True)\n",
      "/var/folders/mn/5t8x6ck57719dt2pg7h0_xl40000gn/T/ipykernel_22199/2775434147.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[new_column_name].fillna(0, inplace=True)\n",
      "/var/folders/mn/5t8x6ck57719dt2pg7h0_xl40000gn/T/ipykernel_22199/2775434147.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[new_column_name].fillna(0, inplace=True)\n",
      "/var/folders/mn/5t8x6ck57719dt2pg7h0_xl40000gn/T/ipykernel_22199/2775434147.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[new_column_name].fillna(0, inplace=True)\n",
      "/var/folders/mn/5t8x6ck57719dt2pg7h0_xl40000gn/T/ipykernel_22199/2775434147.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[new_column_name].fillna(0, inplace=True)\n",
      "/var/folders/mn/5t8x6ck57719dt2pg7h0_xl40000gn/T/ipykernel_22199/2775434147.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[new_column_name].fillna(0, inplace=True)\n",
      "/var/folders/mn/5t8x6ck57719dt2pg7h0_xl40000gn/T/ipykernel_22199/2775434147.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[new_column_name].fillna(0, inplace=True)\n",
      "/var/folders/mn/5t8x6ck57719dt2pg7h0_xl40000gn/T/ipykernel_22199/2775434147.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[new_column_name].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "execution_count": 133
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T22:19:54.792726Z",
     "start_time": "2024-07-17T22:19:54.785403Z"
    }
   },
   "cell_type": "code",
   "source": "feature_df.food_sugar_sum_240min.describe()",
   "id": "bbfb896b6bbf6895",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    26665.000000\n",
       "mean        15.726645\n",
       "std         27.436744\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          1.000000\n",
       "75%         24.000000\n",
       "max        367.000000\n",
       "Name: food_sugar_sum_240min, dtype: float64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 134
  },
  {
   "cell_type": "markdown",
   "id": "da8a1ebe27362999",
   "metadata": {},
   "source": [
    "Add eat counts rolling sum window"
   ]
  },
  {
   "cell_type": "code",
   "id": "7f084da5ede064ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T22:19:54.879410Z",
     "start_time": "2024-07-17T22:19:54.793874Z"
    }
   },
   "source": [
    "# Create 'eating' column based on 'food_calorie'\n",
    "feature_df['eating'] = (feature_df['food_calorie'] > 0).astype(int)\n",
    "\n",
    "# Define time windows in terms of number of periods (5-minute intervals)\n",
    "time_windows = {\n",
    "    '0.5hr': 6,    # 0.5 hours (5 * 5)\n",
    "    '1hr': 12,    # 1 hour (12 * 5)\n",
    "    '2hr': 24,    # 2 hours (24 * 5)\n",
    "    '8hr': 96,    # 8 hours (96 * 5)\n",
    "    '24hr': 288   # 24 hours (288 * 5)\n",
    "}\n",
    "\n",
    "# Calculate count of 'eating' over different time windows\n",
    "for window_name, window_size in time_windows.items():\n",
    "    feature_df[f'eatcnt_{window_name}'] = (\n",
    "        feature_df.groupby('patient_id')['eating']\n",
    "                  .rolling(window=window_size, min_periods=1)\n",
    "                  .sum()\n",
    "                  .reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "# Calculate mean 'eating' over different time windows\n",
    "for window_name, window_size in time_windows.items():\n",
    "    feature_df[f'mean_{window_name}'] = (\n",
    "        feature_df.groupby('patient_id')['eating']\n",
    "                  .rolling(window=window_size, min_periods=1)\n",
    "                  .mean()\n",
    "                  .reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "# Fill NaN values with 0s in the newly created columns\n",
    "eat_columns_to_fill = [f'eatcnt_{window_name}' for window_name in time_windows.keys()] + [f'mean_{window_name}' for window_name in time_windows.keys()]\n",
    "feature_df[eat_columns_to_fill] = feature_df[eat_columns_to_fill].fillna(0)\n"
   ],
   "outputs": [],
   "execution_count": 135
  },
  {
   "cell_type": "markdown",
   "id": "3771b015bffeb260",
   "metadata": {},
   "source": [
    "Add 'WakeTime' points calculator"
   ]
  },
  {
   "cell_type": "code",
   "id": "ebe2997d60caa753",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T22:19:54.918087Z",
     "start_time": "2024-07-17T22:19:54.880325Z"
    }
   },
   "source": [
    "# Calculate cumulative averages for each patient separately\n",
    "feature_df['hr_mean_cum_average'] = feature_df.groupby('patient_id')['hr_mean'].transform(\n",
    "    lambda x: x.expanding().mean())\n",
    "feature_df['hr_std_cum_average'] = feature_df.groupby('patient_id')['hr_std'].transform(lambda x: x.expanding().mean())\n",
    "feature_df['acc_mean_cum_average'] = feature_df.groupby('patient_id')['acc_mean'].transform(\n",
    "    lambda x: x.expanding().mean())\n",
    "feature_df['acc_std_cum_average'] = feature_df.groupby('patient_id')['acc_std'].transform(\n",
    "    lambda x: x.expanding().mean())\n",
    "\n",
    "# Initialize WakeTimePoints column with zeroes\n",
    "feature_df['WakeTimePoints'] = 0\n",
    "\n",
    "'''\n",
    "Conditionally assign points if current value is less than historical average in each patient:\n",
    "- If the current heart rate mean is less than the historical average, assign one point\n",
    "- If the current heart rate standard deviation is less than the historical average, assign one point\n",
    "- If the current accelerometer mean is less than the historical average, assign one point\n",
    "- If the current accelerometer standard deviation is less than the historical average, assign one point\n",
    "'''\n",
    "feature_df.loc[feature_df['hr_mean'] < feature_df['hr_mean_cum_average'], 'WakeTimePoints'] += 1\n",
    "feature_df.loc[feature_df['hr_std'] < feature_df['hr_std_cum_average'], 'WakeTimePoints'] += 1\n",
    "feature_df.loc[feature_df['acc_mean'] < feature_df['acc_mean_cum_average'], 'WakeTimePoints'] += 1\n",
    "feature_df.loc[feature_df['acc_std'] < feature_df['acc_std_cum_average'], 'WakeTimePoints'] += 1\n",
    "\n",
    "# Add binary column where 1 is assigned if WakeTimePoints is greater than 2\n",
    "feature_df['WakeTimePointsBinary'] = (feature_df['WakeTimePoints'] > 2).astype(int)\n",
    "\n",
    "# Compute rolling average over 3 hours (converted to the equivalent number of data points) for each patient\n",
    "feature_df['WakeTimePointsBinary3HrAvg'] = feature_df.groupby('patient_id')['WakeTimePointsBinary'].transform(\n",
    "    lambda x: x.rolling(window=36).mean())\n",
    "\n",
    "# Fill NA values generated by rolling function with 0\n",
    "feature_df['WakeTimePointsBinary3HrAvg'] = feature_df['WakeTimePointsBinary3HrAvg'].fillna(0)\n",
    "\n",
    "# Compute derivative to get the slope between current and previous point in WakeTimePointsBinary3HrAvg for each patient\n",
    "feature_df['WakeTimePoints3HrSlope'] = feature_df.groupby('patient_id')['WakeTimePointsBinary3HrAvg'].transform(\n",
    "    lambda x: x.diff())\n"
   ],
   "outputs": [],
   "execution_count": 136
  },
  {
   "cell_type": "markdown",
   "id": "22843b460839ea8b",
   "metadata": {},
   "source": [
    "Add 'ActivityBouts' and rolling window mean and sum"
   ]
  },
  {
   "cell_type": "code",
   "id": "d0197282d37e6cc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T22:19:54.984302Z",
     "start_time": "2024-07-17T22:19:54.919412Z"
    }
   },
   "source": [
    "# Expanding means for 'hr_mean' and 'acc_mean' for each patient\n",
    "feature_df['hr_mean_hist_avg'] = feature_df.groupby('patient_id')['hr_mean'].transform(lambda x: x.expanding().mean())\n",
    "feature_df['acc_mean_hist_avg'] = feature_df.groupby('patient_id')['acc_mean'].transform(lambda x: x.expanding().mean())\n",
    "\n",
    "# Assign exercise points based on whether current values exceed historical means\n",
    "feature_df['exercise_points'] = ((feature_df['hr_mean'] > feature_df['hr_mean_hist_avg']) &\n",
    "                                 (feature_df['acc_mean'] > feature_df['acc_mean_hist_avg'])).astype(int)\n",
    "\n",
    "# Calculate cumulative exercise points (ActivityBouts) for each patient\n",
    "feature_df['ActivityBouts'] = feature_df.groupby('patient_id')['exercise_points'].transform(\n",
    "    lambda x: x.expanding().sum())\n",
    "\n",
    "# Calculations for given rolling windows\n",
    "for window, hours in [(24, 2), (48, 4), (96, 8), (288, 24)]:\n",
    "    # Calculate rolling mean for ActivityBouts\n",
    "    feature_df[f'Activity{hours}_mean'] = feature_df.groupby('patient_id')['ActivityBouts'] \\\n",
    "        .transform(lambda x: x.rolling(window).mean())\n",
    "\n",
    "    # Calculate rolling sum for ActivityBouts\n",
    "    feature_df[f'Activity{hours}_sum'] = feature_df.groupby('patient_id')['ActivityBouts'] \\\n",
    "        .transform(lambda x: x.rolling(window).sum())\n",
    "\n",
    "# Fill NaN values with 0 for new columns\n",
    "feature_df.fillna({col: 0 for col in ['Activity2_mean', 'Activity2_sum',\n",
    "                                      'Activity4_mean', 'Activity4_sum',\n",
    "                                      'Activity8_mean', 'Activity8_sum',\n",
    "                                      'Activity24_mean', 'Activity24_sum']}, inplace=True)\n",
    "\n",
    "print(feature_df.head())\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     glucose  patient_id  Gender  HbA1c   acc_mean  bvp_mean  \\\n",
      "datetime                                                                       \n",
      "2020-02-13 17:23:32     61.0           1       0    5.5  87.095625 -0.004786   \n",
      "2020-02-13 17:28:32     59.0           1       0    5.5  88.107187 -0.001255   \n",
      "2020-02-13 17:33:32     58.0           1       0    5.5  57.597604  0.020368   \n",
      "2020-02-13 17:38:32     59.0           1       0    5.5  66.899687 -0.009613   \n",
      "2020-02-13 17:43:31     63.0           1       0    5.5  29.774792 -0.012741   \n",
      "\n",
      "                     eda_mean    hr_mean  ibi_mean  temp_mean  ...  \\\n",
      "datetime                                                       ...   \n",
      "2020-02-13 17:23:32  0.848050  82.318333  0.713904  33.171867  ...   \n",
      "2020-02-13 17:28:32  0.632578  75.429167  0.837369  33.136333  ...   \n",
      "2020-02-13 17:33:32  1.544714  75.973400  0.777253  33.244767  ...   \n",
      "2020-02-13 17:38:32  1.839445  77.138967  0.808537  33.315067  ...   \n",
      "2020-02-13 17:43:31  4.880899  81.056267  0.760995  33.660067  ...   \n",
      "\n",
      "                     exercise_points  ActivityBouts  Activity2_mean  \\\n",
      "datetime                                                              \n",
      "2020-02-13 17:23:32                0            0.0             0.0   \n",
      "2020-02-13 17:28:32                0            0.0             0.0   \n",
      "2020-02-13 17:33:32                0            0.0             0.0   \n",
      "2020-02-13 17:38:32                0            0.0             0.0   \n",
      "2020-02-13 17:43:31                0            0.0             0.0   \n",
      "\n",
      "                     Activity2_sum  Activity4_mean  Activity4_sum  \\\n",
      "datetime                                                            \n",
      "2020-02-13 17:23:32            0.0             0.0            0.0   \n",
      "2020-02-13 17:28:32            0.0             0.0            0.0   \n",
      "2020-02-13 17:33:32            0.0             0.0            0.0   \n",
      "2020-02-13 17:38:32            0.0             0.0            0.0   \n",
      "2020-02-13 17:43:31            0.0             0.0            0.0   \n",
      "\n",
      "                     Activity8_mean  Activity8_sum  Activity24_mean  \\\n",
      "datetime                                                              \n",
      "2020-02-13 17:23:32             0.0            0.0              0.0   \n",
      "2020-02-13 17:28:32             0.0            0.0              0.0   \n",
      "2020-02-13 17:33:32             0.0            0.0              0.0   \n",
      "2020-02-13 17:38:32             0.0            0.0              0.0   \n",
      "2020-02-13 17:43:31             0.0            0.0              0.0   \n",
      "\n",
      "                     Activity24_sum  \n",
      "datetime                             \n",
      "2020-02-13 17:23:32             0.0  \n",
      "2020-02-13 17:28:32             0.0  \n",
      "2020-02-13 17:33:32             0.0  \n",
      "2020-02-13 17:38:32             0.0  \n",
      "2020-02-13 17:43:31             0.0  \n",
      "\n",
      "[5 rows x 166 columns]\n"
     ]
    }
   ],
   "execution_count": 137
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T22:19:54.987718Z",
     "start_time": "2024-07-17T22:19:54.985692Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "885a2a253bdc01ef",
   "outputs": [],
   "execution_count": 137
  },
  {
   "cell_type": "code",
   "id": "82c4823ca31b1150",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T22:19:54.995240Z",
     "start_time": "2024-07-17T22:19:54.989480Z"
    }
   },
   "source": [
    "print(feature_df['Activity24_mean'].describe())\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    26665.000000\n",
      "mean       152.451738\n",
      "std        122.809934\n",
      "min          0.000000\n",
      "25%         48.420139\n",
      "50%        140.003472\n",
      "75%        234.197917\n",
      "max        544.701389\n",
      "Name: Activity24_mean, dtype: float64\n"
     ]
    }
   ],
   "execution_count": 138
  },
  {
   "cell_type": "code",
   "id": "fa89819a77c401e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T22:19:56.531777Z",
     "start_time": "2024-07-17T22:19:54.996079Z"
    }
   },
   "source": [
    "# Compute correlation of 'glucose' with other columns\n",
    "# Calculate correlations\n",
    "correlations = feature_df.corr()['glucose']\n",
    "\n",
    "# Sort correlations by absolute value, but keep the original positive/negative correlations\n",
    "sorted_correlations = correlations.reindex(correlations.abs().sort_values(ascending=False).index)\n",
    "\n",
    "# Top 50 correlations\n",
    "top_50_correlations = sorted_correlations.head(50)\n",
    "\n",
    "print(top_50_correlations)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glucose                        1.000000\n",
      "Gender                         0.288043\n",
      "acc_mean_hist_avg             -0.262441\n",
      "acc_mean_cum_average          -0.262441\n",
      "food_sugar_sum_1440min         0.206260\n",
      "food_sugar_sum_120min          0.202874\n",
      "log_eda_max                   -0.200720\n",
      "HbA1c                          0.192463\n",
      "log_eda_q3                    -0.191998\n",
      "log_eda_mean                  -0.189144\n",
      "food_sugar_sum_480min          0.178623\n",
      "log_eda_peaks                 -0.176900\n",
      "acc_x_max                     -0.174532\n",
      "food_total_carb_sum_120min     0.172768\n",
      "log_eda_q1                    -0.171331\n",
      "food_sugar_sum_240min          0.167561\n",
      "acc_x_q3                      -0.166453\n",
      "acc_x_2hr_mean                -0.163795\n",
      "food_sugar_ffwd                0.161010\n",
      "eda_max                       -0.156942\n",
      "acc_x_mean                    -0.153588\n",
      "eda_mean                      -0.150663\n",
      "log_eda_std                   -0.150452\n",
      "eda_q3                        -0.148611\n",
      "acc_std_cum_average           -0.148016\n",
      "eda_q1                        -0.138039\n",
      "food_calorie_sum_120min        0.133666\n",
      "acc_z_std                     -0.132580\n",
      "food_sugar_sum_60min           0.132296\n",
      "food_total_carb_sum_240min     0.131733\n",
      "acc_x_q1                      -0.131232\n",
      "eda_min                       -0.126083\n",
      "acc_std                       -0.123440\n",
      "acc_max                       -0.123220\n",
      "food_total_carb_sum_1440min    0.123219\n",
      "day_period_Afternoon          -0.121612\n",
      "food_total_carb_sum_480min     0.121385\n",
      "acc_z_min                      0.121160\n",
      "acc_y_std                     -0.119563\n",
      "mean_2hr                       0.118760\n",
      "eatcnt_2hr                     0.118525\n",
      "log_acc_2hr_mean              -0.117762\n",
      "acc_y_min                      0.117117\n",
      "acc_x_2hr_max                 -0.113518\n",
      "food_calorie_sum_1440min       0.108772\n",
      "food_calorie_sum_240min        0.108690\n",
      "food_calorie_sum_480min        0.107942\n",
      "eda_std                       -0.107351\n",
      "WakeTimePointsBinary3HrAvg     0.106918\n",
      "acc_y_max                     -0.104682\n",
      "Name: glucose, dtype: float64\n"
     ]
    }
   ],
   "execution_count": 139
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T22:19:56.538983Z",
     "start_time": "2024-07-17T22:19:56.533718Z"
    }
   },
   "cell_type": "code",
   "source": "feature_df.shape",
   "id": "2b3139f3c8518a06",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26665, 166)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 140
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T22:19:56.552261Z",
     "start_time": "2024-07-17T22:19:56.540695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Assuming feature_df is your DataFrame\n",
    "nan_counts = feature_df.isnull().sum().sort_values(ascending=False)\n",
    "print(nan_counts.head(45))\n"
   ],
   "id": "3d4621d0365616b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WakeTimePoints3HrSlope      16\n",
      "glucose                      0\n",
      "food_calorie_sum_1440min     0\n",
      "day_period_Night             0\n",
      "food_calorie_sum_10min       0\n",
      "food_calorie_sum_30min       0\n",
      "food_calorie_sum_60min       0\n",
      "food_calorie_sum_120min      0\n",
      "food_calorie_sum_240min      0\n",
      "food_calorie_sum_480min      0\n",
      "food_protein_sum_10min       0\n",
      "day_period_Evening           0\n",
      "food_protein_sum_30min       0\n",
      "food_protein_sum_60min       0\n",
      "food_protein_sum_120min      0\n",
      "food_protein_sum_240min      0\n",
      "food_protein_sum_480min      0\n",
      "food_protein_sum_1440min     0\n",
      "food_sugar_sum_10min         0\n",
      "food_sugar_sum_30min         0\n",
      "day_period_Morning           0\n",
      "day_period_Afternoon         0\n",
      "food_sugar_sum_120min        0\n",
      "minutes_since_start          0\n",
      "food_sugar_ffwd              0\n",
      "food_protein_ffwd            0\n",
      "food_total_fat_ffwd          0\n",
      "log_eda_peaks                0\n",
      "log_eda_max                  0\n",
      "log_eda_q3                   0\n",
      "log_eda_std                  0\n",
      "log_eda_mean                 0\n",
      "log_eda_q1                   0\n",
      "log_bvp_max                  0\n",
      "log_acc_2hr_mean             0\n",
      "log_hr_std                   0\n",
      "log_temp_std                 0\n",
      "minutesfrommidnight          0\n",
      "hoursfrommidnight            0\n",
      "day_of_month                 0\n",
      "is_weekend                   0\n",
      "food_sugar_sum_60min         0\n",
      "food_sugar_sum_240min        0\n",
      "patient_id                   0\n",
      "food_sugar_sum_480min        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 141
  },
  {
   "cell_type": "code",
   "id": "56fb4228c093f8c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T22:19:59.535172Z",
     "start_time": "2024-07-17T22:19:56.553719Z"
    }
   },
   "source": [
    "feature_df.to_csv('feature_df.csv', index=True)"
   ],
   "outputs": [],
   "execution_count": 142
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "37px",
    "width": "165px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "304.594px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
